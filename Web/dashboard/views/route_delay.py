"""
F-09: ë…¸ì„ ë³„ ì§€ì—° ë¶„ì„ í™”ë©´
ì„ íƒí•œ ë‚ ì§œ ë²”ìœ„ì™€ ë…¸ì„ ì— ëŒ€í•´ ì¼ë³„/ì‹œê°„ëŒ€ë³„ í‰ê·  ì§€ì—° ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from typing import Dict, Optional
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from utils.logger import logger
    from utils.errors import display_error_in_streamlit
except ImportError:
    import logging
    logger = logging.getLogger(__name__)
    def display_error_in_streamlit(e, msg=None):
        import streamlit as st
        st.error(f"âŒ {msg or str(e)}")


def load_route_delay_data(use_local: bool = True) -> Optional[pd.DataFrame]:
    """
    ë…¸ì„ ë³„ ì§€ì—° ë°ì´í„° ë¡œë”©
    
    Args:
        use_local: ë¡œì»¬ ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        DataFrame ë˜ëŠ” None
    """
    try:
        if use_local:
            # ë¡œì»¬ Parquet íŒŒì¼ ì½ê¸°
            data_path = Path(__file__).parent.parent.parent / "data" / "curated" / "route_delay_by_hour"
            
            if not data_path.exists():
                logger.warning(f"ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
                return None
            
            # PySpark ì—†ì´ pandasë¡œ ì§ì ‘ ì½ê¸° (ê°„ë‹¨í•œ ë²„ì „)
            # ì‹¤ì œë¡œëŠ” PySparkë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ë¯¸ë¦¬ ë³€í™˜ëœ CSVë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ
            import pyarrow.parquet as pq
            
            table = pq.read_table(data_path)
            df = table.to_pandas()
            
            return df
        else:
            # S3 ë˜ëŠ” DynamoDBì—ì„œ ì½ê¸°
            # TODO: êµ¬í˜„ í•„ìš”
            return None
            
    except Exception as e:
        logger.error(f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return None


def filter_data_by_state(df: pd.DataFrame, filter_state: Dict) -> pd.DataFrame:
    """
    í•„í„° ìƒíƒœì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
    
    Args:
        df: ì›ë³¸ DataFrame
        filter_state: í•„í„° ìƒíƒœ
    
    Returns:
        í•„í„°ë§ëœ DataFrame
    """
    filtered_df = df.copy()
    
    # ë‚ ì§œ í•„í„°
    if filter_state.get('date_range'):
        start_date, end_date = filter_state['date_range']
        if 'aggregation_date' in filtered_df.columns:
            filtered_df['aggregation_date'] = pd.to_datetime(filtered_df['aggregation_date'])
            filtered_df = filtered_df[
                (filtered_df['aggregation_date'].dt.date >= start_date) &
                (filtered_df['aggregation_date'].dt.date <= end_date)
            ]
    
    # ìš”ì¼ í•„í„°
    if filter_state.get('day_of_week'):
        if 'weekday' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['weekday'].isin(filter_state['day_of_week'])]
    
    # ë…¸ì„  í•„í„°
    if filter_state.get('selected_routes') and len(filter_state['selected_routes']) > 0:
        if 'Journey_Pattern_ID' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['Journey_Pattern_ID'].isin(filter_state['selected_routes'])]
    
    # ì‹œê°„ëŒ€ í•„í„°
    if filter_state.get('time_range'):
        time_start, time_end = filter_state['time_range']
        if 'hour' in filtered_df.columns:
            filtered_df = filtered_df[
                (filtered_df['hour'] >= time_start) &
                (filtered_df['hour'] <= time_end)
            ]
    
    # ìš´ì˜ì í•„í„°
    if filter_state.get('operator'):
        if 'Operatorname' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['Operatorname'] == filter_state['operator']]
    
    return filtered_df


def render_route_delay_view(filter_state: Dict):
    """
    ë…¸ì„ ë³„ ì§€ì—° ë¶„ì„ í™”ë©´ ë Œë”ë§
    
    Args:
        filter_state: í•„í„° ìƒíƒœ
    """
    st.header("ë…¸ì„ ë³„ ì§€ì—° ë¶„ì„")
    
    try:
        # ë¡œë”© ì¸ë””ì¼€ì´í„°
        with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            # ë°ì´í„° ë¡œë”©
            df = load_route_delay_data(use_local=True)
        
        if df is None or df.empty:
            st.warning("âš ï¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ETL íŒŒì´í”„ë¼ì¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            st.info("ğŸ’¡ ì‹¤í–‰ ë°©ë²•: `python -m etl.spark_etl`")
            return
        
        # í•„í„° ì ìš©
        filtered_df = filter_data_by_state(df, filter_state)
        
        if filtered_df.empty:
            st.warning("âš ï¸ ì„ íƒí•œ í•„í„° ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # KPI ì¹´ë“œ
        col1, col2, col3, col4 = st.columns(4)
        
        avg_delay = filtered_df['avg_delay'].mean() if 'avg_delay' in filtered_df.columns else 0
        max_delay = filtered_df['max_delay'].max() if 'max_delay' in filtered_df.columns else 0
        total_trips = filtered_df['trip_count'].sum() if 'trip_count' in filtered_df.columns else 0
        congestion_rate = filtered_df['congestion_rate'].mean() if 'congestion_rate' in filtered_df.columns else 0
        
        with col1:
            st.metric("í‰ê·  ì§€ì—° ì‹œê°„", f"{avg_delay:.1f}ì´ˆ")
        with col2:
            st.metric("ìµœëŒ€ ì§€ì—° ì‹œê°„", f"{max_delay:.1f}ì´ˆ")
        with col3:
            st.metric("ì´ ìš´í–‰ íšŸìˆ˜", f"{int(total_trips):,}íšŒ")
        with col4:
            st.metric("í‰ê·  í˜¼ì¡ë¥ ", f"{congestion_rate:.1f}%")
        
        st.markdown("---")
        
        # ì¼ë³„ í‰ê·  ì§€ì—° ê·¸ë˜í”„
        st.subheader("ì¼ë³„ í‰ê·  ì§€ì—° ì‹œê°„")
        
        if 'aggregation_date' in filtered_df.columns and 'avg_delay' in filtered_df.columns:
            daily_delay = filtered_df.groupby('aggregation_date')['avg_delay'].mean().reset_index()
            daily_delay['aggregation_date'] = pd.to_datetime(daily_delay['aggregation_date'])
            daily_delay = daily_delay.sort_values('aggregation_date')
            
            fig = px.line(
                daily_delay,
                x='aggregation_date',
                y='avg_delay',
                title="ì¼ë³„ í‰ê·  ì§€ì—° ì‹œê°„ ì¶”ì´",
                labels={'aggregation_date': 'ë‚ ì§œ', 'avg_delay': 'í‰ê·  ì§€ì—° ì‹œê°„ (ì´ˆ)'}
            )
            fig.update_traces(line_color='#1f77b4', line_width=2)
            st.plotly_chart(fig, use_container_width=True)
        
        # ì‹œê°„ëŒ€ë³„ í‰ê·  ì§€ì—° ê·¸ë˜í”„
        st.subheader("ì‹œê°„ëŒ€ë³„ í‰ê·  ì§€ì—° ì‹œê°„")
        
        if 'hour' in filtered_df.columns and 'avg_delay' in filtered_df.columns:
            hourly_delay = filtered_df.groupby('hour')['avg_delay'].mean().reset_index()
            hourly_delay = hourly_delay.sort_values('hour')
            
            fig = px.bar(
                hourly_delay,
                x='hour',
                y='avg_delay',
                title="ì‹œê°„ëŒ€ë³„ í‰ê·  ì§€ì—° ì‹œê°„",
                labels={'hour': 'ì‹œê°„ (ì‹œ)', 'avg_delay': 'í‰ê·  ì§€ì—° ì‹œê°„ (ì´ˆ)'}
            )
            fig.update_traces(marker_color='#ff7f0e')
            st.plotly_chart(fig, use_container_width=True)
        
        # ë…¸ì„ ë³„ ì§€ì—° ë¹„êµ
        st.subheader("ë…¸ì„ ë³„ ì§€ì—° ë¹„êµ")
        
        if 'Journey_Pattern_ID' in filtered_df.columns and 'avg_delay' in filtered_df.columns:
            route_delay = filtered_df.groupby('Journey_Pattern_ID')['avg_delay'].mean().reset_index()
            route_delay = route_delay.sort_values('avg_delay', ascending=False).head(10)
            
            fig = px.bar(
                route_delay,
                x='Journey_Pattern_ID',
                y='avg_delay',
                title="ë…¸ì„ ë³„ í‰ê·  ì§€ì—° ì‹œê°„ (ìƒìœ„ 10ê°œ)",
                labels={'Journey_Pattern_ID': 'ë…¸ì„  ID', 'avg_delay': 'í‰ê·  ì§€ì—° ì‹œê°„ (ì´ˆ)'}
            )
            fig.update_xaxes(tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)
        
        # ë°ì´í„° í…Œì´ë¸”
        with st.expander("ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
            st.dataframe(filtered_df.head(100))
            
    except Exception as e:
        display_error_in_streamlit(e, "ë…¸ì„ ë³„ ì§€ì—° ë¶„ì„ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

